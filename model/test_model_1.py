from IPython.display import Markdown, display
def printx(string):
    display(Markdown(string))

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

import os
from yandex_cloud_ml_sdk import YCloudML

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

from glob import glob
from tqdm.auto import tqdm
import pandas as pd

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

from yandex_cloud_ml_sdk.search_indexes import (
    StaticIndexChunkingStrategy,
    HybridSearchIndexType,
    TextSearchIndexType,
    VectorSearchIndexType,
    ReciprocalRankFusionIndexCombinationStrategy,
)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Исходный код - как по=хорошему должно быть
# folder_id = os.environ["folder_id"]
# api_key = os.environ["api_key"]
#
# sdk = YCloudML(folder_id=folder_id, auth=api_key)

# Наш код
sdk = YCloudML(folder_id="b1g6rjppcrrhq56lsqr0", auth="AQVNxTuU2_Efl4APdsHSsNBwMzOpuLziy4TeHEr2")

# Раскомментируйте, если хотите подробнее смотреть, что делает SDK
# sdk.setup_default_logging(log_level='DEBUG')

# Модель стандартной YANDEX GPT
# model = sdk.models.completions("yandexgpt", model_version="rc")

# Модель LLama моя ggs
model = sdk.models.completions("gpt://b1g6rjppcrrhq56lsqr0/llama-lite/latest@tamr074gv096dpj8fpg52")

# Модель LLama моя new_fine_tuning_model
# model = sdk.models.completions("gpt://b1g6rjppcrrhq56lsqr0/llama-lite/latest@tamrv6si2nqsg5ea5srge")

# Модель с новым количеством примеров
# model = sdk.models.completions("yandexgpt", model_version="rc")

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

message_1 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: Север \nОтд7 пах с св 41/501\nОтд20 20/281 по пу 61/793\nОтд 3 пах подс.60/231\nПо пу 231\n\nДиск к. Сил отд 7. 32/352\nПу- 484\nДиск под Оз п езубов 20/281\nДиск под с. Св отд 10 83/203 пу-1065га"
message_2 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: Восход\nПосев кук-24/252га\n24%\nПредпосевная культ\nПод кук-94/490га46%\nСЗРоз пш-103/557га\n25%\nПодкормка оз рапс-\n152га , 100%, подкормка овса-97га, 50%\nДовсходовое боронование подсолнечника-524\nга, 100%."
message_3 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: 23.10\nВнесение мин удобрений под оз пшеницу 2025 г ПУ Юг 216/7698\nОтд 17-216/1877"
message_4 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: Пахота зяби под сою \nПо Пу 13/1464\nОтд 17 13/203\n\nДисков сах св\nПо Пу 36/1391\nОтд 16 25/25\nОтд 17 11/664\n\n2-е диск сах св под пш\nПо Пу 111/1288\nОтд 17 111/596\n\nВыравн зяби под сах св\nПо Пу 30/1395\nОтд 11 30/491"
message_5 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: ТСК \n Вырав-ие зяби под сою 187 га/ с нарастающим 740 га (13%) Остаток 5357 га\nОсадки 1 мм"
message_6 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: \n Вырав-ие зяби под сах/свёклу По ПУ 67/912 Отд 12 67/376"
message_7 = "Проанализируй сообщение и распредели по группам\n Вот пример сообщения: ТСК \n Выравниваниеие зяби под сою 187 га/ с нарастающим 740 га (13%) Остаток 5357 га\nОсадки 1 мм"

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Создание потока и ассистента

def create_thread():
    return sdk.threads.create(ttl_days=1, expiration_policy="static")

def create_assistant(model, tools=None):
    kwargs = {}
    if tools and len(tools) > 0:
        kwargs = {"tools": tools}
    return sdk.assistants.create(
        model, ttl_days=1, expiration_policy="since_last_active", **kwargs
    )

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# thread = create_thread()
# assistant = create_assistant(model)
#
# assistant.update(
#     instruction="""Ты - опытный сомелье, задача которого - консультировать пользователя в
#     вопросах выбора вина."""
# )
#
# thread.write("Привет! Какое вино посоветуете?")
#
# run = assistant.run(thread)
# result = run.wait()
#
# printx(result.text)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# thread.write("Я буду есть стейк!")
#
# run = assistant.run(thread)
# result = run.wait()
#
# printx(result.text)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# for msg in list(thread)[::-1]:
#     printx(f"**{msg.author.role}:** {msg.text}")

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Удаление ассистента - для отсутствия продолжения запоминания диалога
# thread.delete()
# assistant.delete()

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Прикручивание RAG
def get_token_count(filename):
    with open(filename, "r", encoding="utf8") as f:
        return len(model.tokenize(f.read()))

def get_file_len(filename):
    with open(filename, encoding="utf-8") as f:
        l = len(f.read())
    return l

d = [
    {
        "File": fn,
        "Tokens": get_token_count(fn),
        "Chars": get_file_len(fn),
        # "Category": fn.split("/")[1], Нам не нужно из-за другой архитектуры хранения данных
    }
    # for fn in glob("data/*/*.md") Нам не нужно из-за другой архитектуры хранения данных
    for fn in glob("data/*.md")
    # if fn.count("/") == 2 Нам не нужно из-за другой архитектуры хранения данны
]

df = pd.DataFrame(d)
print(df)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# df.groupby("Category").agg({"Tokens": ("min", "mean", "max")})

#Авантюра
print(df.agg({"Tokens": ("min", "mean", "max")}))

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Загрузка файлов в облако
def upload_file(filename):
    return sdk.files.upload(filename, ttl_days=1, expiration_policy="static")

df["Uploaded"] = df["File"].apply(upload_file)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Строим индекс

# Гибридный поиск
op = sdk.search_indexes.create_deferred(
    df["Uploaded"],
    index_type=HybridSearchIndexType(
        chunking_strategy=StaticIndexChunkingStrategy(
            max_chunk_size_tokens=150, chunk_overlap_tokens=20 # Надо выяснить что нам надо
        ),
        # combination_strategy=ReciprocalRankFusionIndexCombinationStrategy(), # Универсально
        #Возможные настройки но первое всегда chunking_strategy
        # vector_search_index=VectorSearchIndexType(
        #           doc_embedder_uri="emb://<идентификатор_каталога>/text-search-doc/latest",
        #           query_embedder_uri="emb://<идентификатор_каталога>/text-search-query/latest"),
        # normalization_strategy='L2',
        combination_strategy=ReciprocalRankFusionIndexCombinationStrategy(
            k=20
            #weights=[0.7, 0.3]
        )
    ),
)

# Векторный поиск
# op = sdk.search_indexes.create_deferred(
#     df["Uploaded"],
#     index_type=HybridSearchIndexType(
# #        doc_embedder_uri="emb://<идентификатор_каталога>/text-search-doc/latest", Это по умолчанию стоит на модель эмбеддингов Foundation Models
# #       query_embedder_uri="emb://<идентификатор_каталога>/text-search-query/latest", Это по умолчанию стоит на модель эмбеддингов Foundation Models
#         chunking_strategy=StaticIndexChunkingStrategy(
#             max_chunk_size_tokens=700, chunk_overlap_tokens=300 #Изменяем для улучшения
#         )
#     ),
# )

# Поиск по ключевым словам
# op = sdk.search_indexes.create_deferred(
#     df["Uploaded"],
#     index_type=TextSearchIndexType(
#         chunking_strategy=StaticIndexChunkingStrategy(
#             max_chunk_size_tokens=1000, chunk_overlap_tokens=100 #Изменяем для улучшения
#         ),
#     ),
# )

index = op.wait()

# Нам не нужно из-за другой архитектуры хранения данных
# op = index.add_files_deferred(df[df["Category"]=="regions"]["Uploaded"])
# xfiles = op.wait()

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------



# Как будто потом это делаем
# search_tool = sdk.tools.search_index(index)
#
# assistant = create_assistant(model, tools=[search_tool])
# thread = create_thread()

# Не наша инструкция
# instruction = """
# Ты - опытный сомелье, в задачу которого входит отвечать на вопросы пользователя про вина
# и рекомендовать лучшие вина к еде. Посмотри на всю имеющуюся в твоем распоряжении информацию
# и выдай одну или несколько лучших рекомендаций. Если что-то непонятно, то лучше уточни информацию
# у пользователя.
# """

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# thread.write("Какое вино подходит к стейку?")
# run = assistant.run(thread)
#
# result = run.wait()
# printx(result.text)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# def print_citations(result):
#     for citation in result.citations:
#         for source in citation.sources:
#             if source.type != "filechunk":
#                 continue
#             print("------------------------")
#             printx(source.parts[0])
#
# print_citations(result)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Удвление потока
# thread.delete()

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

#Первая таблица соответствий
# with open("trash/culture.md", encoding="utf-8") as f:
#     culture = f.readlines()
# fw = "".join(culture)
#
# tokens = len(model.tokenize(fw))
# print(f"Токенов: {tokens}, {len(fw)/tokens} chars/token")
#
# header = culture[:2]
#
# chunk_size = 200 #600 * 3  # Надо выяснить что нам надо
#
# s = header.copy()
# uploaded_culture = []
# for x in culture[2:]:
#     s.append(x)
#     if len("".join(s)) > chunk_size:
#         id = sdk.files.upload_bytes(
#             "".join(s).encode(), ttl_days=5, expiration_policy="static",
#             mime_type="text/markdown",
#         )
#         #printx("".join(s))
#         uploaded_culture.append(id)
#         s = header.copy()
# print(f"Uploaded {len(uploaded_culture)} table chunks")
#
# #Авантюра
# op = sdk.search_indexes.create_deferred(
#     uploaded_culture,
#     index_type=HybridSearchIndexType(
#         chunking_strategy=StaticIndexChunkingStrategy(
#             max_chunk_size_tokens=1000, chunk_overlap_tokens=100 # Надо выяснить что нам надо
#         ),
#         combination_strategy=ReciprocalRankFusionIndexCombinationStrategy(), # Универсально
# #         #Возможные настройки но первое всегда chunking_strategy
# #         # vector_search_index=VectorSearchIndexType(
# #         #           doc_embedder_uri="emb://<идентификатор_каталога>/text-search-doc/latest",
# #         #           query_embedder_uri="emb://<идентификатор_каталога>/text-search-query/latest"),
# #         # normalization_strategy='L2',
# #         # combination_strategy=ReciprocalRankFusionIndexCombinationStrategy(
# #         # k=60
# #         # )
#     ),
# )
#
# # op = index.add_files_deferred(uploaded_culture)
# index = op.wait()
#
# #-----------------------------------------------------------------
# #-----------------------------------------------------------------
# #-----------------------------------------------------------------
# #-----------------------------------------------------------------
# #-----------------------------------------------------------------

#Вторая таблица соответствий
# with open("trash/operations.md", encoding="utf-8") as f:
#     operations = f.readlines()
# fw = "".join(operations)
#
# tokens = len(model.tokenize(fw))
# print(f"Токенов: {tokens}, {len(fw)/tokens} chars/token")
#
# header = operations[:2]
#
# chunk_size = 100 # 500 * 3 # Надо выяснить что нам надо
#
# s = header.copy()
# uploaded_operations = []
# for x in operations[2:]:
#     s.append(x)
#     if len("".join(s)) > chunk_size:
#         id = sdk.files.upload_bytes(
#             "".join(s).encode(), ttl_days=5, expiration_policy="static",
#             mime_type="text/markdown",
#         )
#         #printx("".join(s))
#         uploaded_operations.append(id)
#         s = header.copy()
# print(f"Uploaded {len(uploaded_operations)} table chunks")
#
# op = index.add_files_deferred(uploaded_operations)
# xfiles = op.wait()

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

# Тестовый пример из исходник
# thread = create_thread()
#
# thread.write("Какое вино подходит к стейку?")
# run = assistant.run(thread)
#
# result = run.wait()
# printx(result.text)
# print_citations(result)

# Наш пример
thread = create_thread()
search_tool = sdk.tools.search_index(index)
assistant = create_assistant(model, tools=[search_tool])

# Наша инструкция
instruction = "Ты — помощник агронома, который должен распределить информацию из собщения по группам: Дата, Подразделение, Операция, Культура, За день га, С начала операции га,Вал за день ц, Вал с начала ц"


_ = assistant.update(instruction=instruction)

thread.write(message_1)
run = assistant.run(thread)
result = run.wait()
print(result.text)

#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------

thread.delete()
assistant.delete()